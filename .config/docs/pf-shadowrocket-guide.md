### 第一部分：简历诊断报告

**1. 总体匹配度：中偏高 (匹配度约 80%)**
*   **候选人画像：** 约4.5年经验的Java后端开发，正处于从中级向高级过渡的阶段。技术栈（Spring Cloud, Redis, MySQL, Kafka）与JD高度重合。
*   **亮点：** 简历中体现了明显的**AI转型意向与实践**（RAG架构、Text-to-SQL、向量数据库），这非常符合JD中“AI方向”的要求。同时，具备较强的**运维/监控系统开发经验**（ClickHouse, Ansible），符合JD中对“处理网络通信、基础配置”及“高可用”的需求。
*   **定位建议：** 候选人经验年限卡在“中级”与“高级”之间。如果是招聘“中级”，此人是高配；如果是“高级”，需重点考察架构设计深度及AI项目的真实落地程度。

**2. 优势/亮点**
*   **AI 落地经验：** 简历中明确提到了“AI魔方”项目，涉及RAG、向量数据库（Milvus）、Text-to-SQL，与JD中要求的LangChain、Agent业务高度匹配。
*   **大数据处理能力：** 提到的“10TB日均吞吐量”和 ClickHouse/Kafka 经验，若属实，证明其具备处理高并发、大数据量的能力，优于普通CRUD工程师。
*   **全栈/DevOps意识：** 熟悉Ansible、Docker及Shell脚本，能弥补纯开发在部署和运维上的短板。

**3. 水分/疑点预警 (重点考察区)**
*   **数据量级存疑：** “日均吞吐量 10TB”是一个非常庞大的数字（相当于全天平均120MB/s写入，峰值可能更高）。需要核实集群规模、硬件配置及数据真实性（是生产环境还是压测数据？）。
*   **AI 项目周期短：** “AI魔方”项目时间是 2024.11 至今（仅2-3个月）。在如此短的时间内完成从RAG架构到“智能低代码平台”的开发，极有可能只是集成了现成框架或API，而非底层开发。需要通过追问确认其核心贡献。
*   **性能优化指标：** “Full GC 频率降低 60%+”、“QPS 提升至 3000+”这类精确数字，面试中需让其复盘具体的排查过程和计算方式，防止是编造的KPI。

### 第三部分：核心面试题集 (Probing Protocol)

#### 模块一：高并发与大数据处理 (建议时长: 12分钟)

**Q1: 关于“统一监控平台”项目，你提到了日均 10TB 的日志吞吐量。请描述一下这个数据管道的架构是如何设计的？使用了多少节点来支撑这个量级？**
*   **简历锚点:** “基于 Kafka+ClickHouse 构建实时日志分析系统（日均吞吐量 10TB...）”
*   **考察目标:** [真实性] 验证超大数据量项目的真实性及架构合理性。
*   **参考答案:** 应该提到 Filebeat -> Kafka (多分区) -> Flink/Java Consumer -> ClickHouse (分片/副本) 的完整链路。关键在于 Kafka 的 Partition 数量规划、ClickHouse 的集群规模（10TB 通常需要较多节点或极高性能磁盘）。
*   **评价标准:**
    *   *好:* 能清晰说出机器数量（例如：Kafka 5节点，CH 10节点等）、磁盘类型（SSD/HDD），以及数据流转的瓶颈点。
    *   *差:* 支支吾吾说不清集群配置，或者用单机/小集群声称处理了 10TB 数据。

> **[追问1: 原理与细节深挖]**
> *   **提问:** 在这么大的写入量下，ClickHouse 的写入性能是如何保证的？你是如何处理 Kafka 到 ClickHouse 的消费积压问题的？
> *   **考察目标:** [技术深度] 考察对 ClickHouse 批量写入机制、Kafka 消费者组及背压（Backpressure）的处理。
> *   **参考答案:** 必须提到 **批量写入** (Batch Insert)，不能单条插；ClickHouse 的 MergeTree 引擎特性；Kafka 多线程消费或增加 Partition；写入前的聚合策略。
> *   **评价标准:**
>     *   *好:* 提到具体的批次大小（如 10万条或 5秒一批），提到 ClickHouse 的 `Buffer` 表或异步写入机制。
>     *   *差:* 认为可以实时单条写入，不知道 ClickHouse 的高频写入会导致 merge 压力过大。

> **[追问2: 极端场景设计]**
> *   **提问:** 如果 ClickHouse 集群因为 Merge 任务过重导致写入拒绝，或者 Kafka 某个分区发生严重的数据倾斜，你会如何设计降级或恢复方案？
> *   **考察目标:** [系统设计/稳定性] 考察高可用保障及线上故障处理能力。
> *   **参考答案:** 降级方案（如写入本地文件/S3 稍后回放）、Kafka 重新分区（Rebalance）、削峰填谷策略、ClickHouse 扩容或调整 TTL 策略。
> *   **评价标准:**
>     *   *好:* 有具体的熔断机制，知道数据倾斜的原理（Key 选择不当）并能提出重新 Hash 的方案。
>     *   *差:* 只有重启服务这一种方案，或者不知道什么是数据倾斜。

#### 模块二：AI 工程化与 RAG 实战 (建议时长: 13分钟)

**Q2: 在“AI魔方”项目中，你实现了自然语言转 SQL (Text-to-SQL) 和 RAG 架构。请详细讲讲你是如何处理 数据库 Schema 的上下文注入的？如何保证生成的 SQL 是可执行且准确的？**
*   **简历锚点:** “实现自然语言到 SQL 的智能转换... 动态 Schema 管理... 多轮语义校准”
*   **考察目标:** [AI落地能力] 区分是简单的 Prompt 拼接还是有工程化处理。
*   **参考答案:** 涉及到 Prompt Engineering (System Prompt 包含 Schema 定义)、Context Window 限制（不能把几千张表都塞进去，需要先检索相关表）、Few-shot Learning (提供示例)、以及执行前的校验（Syntax Check 或 `EXPLAIN`）。
*   **评价标准:**
    *   *好:* 提到**Schema 检索/过滤**（先用向量搜出相关表，再注入 Prompt），提到使用了 Rerank 模型优化检索，或者有后置的 SQL 校验修正机制。
    *   *差:* 仅回答“把表结构发给 GPT”，不考虑 Token 限制，没有防幻觉机制。

> **[追问1: 向量检索细节]**
> *   **提问:** 你提到了使用 Milvus 和 `bge-reranker`。请问在构建向量库时，文本切片（Chunking）的策略是什么？Rerank 在你的链路中起到了什么具体作用？
> *   **考察目标:** [技术细节] 考察对 RAG 核心组件的理解。
> *   **参考答案:** Chunk size 的选择（如 512/1024 tokens），重叠（Overlap）设置。Rerank 是为了对初步检索回来的 Top-K 进行精排，提高准确率，解决向量相似度主要基于语义而非精确匹配的问题。
> *   **评价标准:**
>     *   *好:* 能解释为什么要 Rerank（向量召回有时不准），能根据业务场景（如SQL生成）调整切片策略（如按表定义切片）。
>     *   *差:* 不知道为什么切片，不知道 Rerank 解决了什么问题。

> **[追问2: 安全与边界]**
> *   **提问:** 如果用户通过自然语言输入了恶意的指令（比如“删除所有数据”或 Prompt Injection），你的系统在工程层面是如何防御的？
> *   **考察目标:** [安全性/架构观] 考察 AI 系统在生产环境的安全意识。
> *   **参考答案:** 数据库权限控制（只给 Read 权限）、Prompt 防御（System Prompt 强指令）、SQL 解析器白名单（禁止 DROP/DELETE/UPDATE）、人工审核环节。
> *   **评价标准:**
>     *   *好:* **必须提到数据库层面的权限隔离**（最底层的保障），其次是应用层的解析拦截。
>     *   *差:* 认为完全靠大模型自己判断是否执行，没有硬性的安全兜底。

#### 模块三：Java 核心与性能调优 (建议时长: 10分钟)

**Q3: 简历中提到通过 Redisson 分布式锁解决了秒杀超卖问题，QPS 提升至 3000+。请问在这个场景下，你是如何设置锁的超时时间的？如果业务执行时间超过了锁过期时间，Redisson 是怎么处理的？**
*   **简历锚点:** “Redis 分布式锁（Redisson）解决秒杀场景超卖... QPS 3000+”
*   **考察目标:** [原理掌握] 考察对 Redisson "Watchdog" 机制的理解。
*   **参考答案:** 默认 30s，Watchdog（看门狗）机制会自动续期（每 10s 检查一次，如果线程还持有锁就续期）。
*   **评价标准:**
    *   *好:* 清晰解释 Watchdog 自动续期原理，以及显式设置 leaseTime 会导致 Watchdog 失效的区别。
    *   *差:* 不知道看门狗机制，认为只能手动估算一个很长的过期时间。

> **[追问1: 极端并发场景]**
> *   **提问:** 秒杀场景下 QPS 3000+，如果大量请求在抢同一把锁（Hot Key），Redis 会成为瓶颈吗？你会怎么进一步优化？
> *   **考察目标:** [性能优化] 考察从“分布式锁”到“分段锁”或“库存扣减策略”的思维跃迁。
> *   **参考答案:** 会成为瓶颈。优化方案：**分段锁**（将库存拆分为 10 份，Key_0 到 Key_9，随机路由或哈希路由），或者将库存扣减下沉到 Redis Lua 脚本中原子执行，减少网络 IO。
> *   **评价标准:**
>     *   *好:* 提出分段锁（ConcurrentHashMap 思想）或 Redis Lua 方案。
>     *   *差:* 认为 Redis 单机能无限抗压，没有拆分热点的意识。

> **[追问2: 数据库与缓存一致性]**
> *   **提问:** 扣减完 Redis 缓存中的库存后，如何保证 MySQL 中的库存数据最终一致？如果更新数据库失败了怎么办？
> *   **考察目标:** [架构设计] 考察分布式事务/最终一致性方案。
> *   **参考答案:** 延时双删（不推荐）、MQ 异步消息队列（可靠性投递）实现最终一致性、TCC 或 Seata（视复杂度而定）。推荐 MQ 方案：Redis 扣减成功 -> 发 MQ -> 消费者慢慢扣减 DB。
> *   **评价标准:**
>     *   *好:* 推荐使用 MQ 进行削峰和异步同步，考虑到消息丢失或重复消费的问题（幂等性）。
>     *   *差:* 同步更新 DB，无法应对高并发；忽略了更新失败后的回滚或重试。

#### 模块四：JVM 调优 (若有时间，快速考察)

**Q4: 你提到通过 Arthas 诊断并优化了 Full GC，频率降低 60%。请还原一下当时的场景：是什么原因导致了频繁 Full GC？你调整了哪些具体参数？**
*   **简历锚点:** “通过 Arthas 诊断 GC 问题（CMS/G1），实现 Full GC 频率降低 60%+”
*   **考察目标:** [真实性] 避免“背诵式”调优，要求具体案例。
*   **参考答案:** 常见原因：Metaspace 不足、大对象直接进老年代、Young 区过小导致对象过早晋升（Premature Promotion）。调整参数如 `-Xmn` (增大年轻代), `-XX:MaxGCPauseMillis` (G1), `-XX:PretenureSizeThreshold`。
*   **评价标准:**
    *   *好:* 能说出具体的内存泄露点（如某个导出功能加载了全量数据）或参数配置失误（如年轻代太小）。
    *   *差:* 只会说“调整了堆大小”，说不出具体的内存区域变化，或者混淆了 CMS 和 G1 的参数。

### 面试官评分辅助建议：

*   **S (Strong Hire):** 对 10TB 数据处理有清晰的物理架构认知，能深入解释 RAG 中 Schema 注入与 Token 限制的工程细节，Redis/MySQL 优化有具体的抗压策略。
*   **H (Hire):** 核心业务逻辑清晰，AI 部分能说出基本原理但工程深度一般，Java 基础扎实，能够胜任中级开发并有培养潜力。
*   **N (No Hire):** 10TB 数据量无法自圆其说（如单机处理），AI 项目仅限于调用 API 且不懂原理，对高并发下的锁竞争和数据库一致性缺乏方案。